{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35772683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings #library to ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ipywidgets as widgets #widgets for voila deployment\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08180fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # for extracting html content\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2a90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aaf6f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "import sklearn\n",
    "import statsmodels.api as sm \n",
    "import scipy.stats as st\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79875346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n",
      "Enabling: voila\n",
      "- Writing config: D:\\anaconda3\\etc\\jupyter\n",
      "    - Validating...\n",
      "      voila 0.4.0 ok\n"
     ]
    }
   ],
   "source": [
    "#!pip install voila\n",
    "#!pip install widgetsnbextension\n",
    "#!pip uninstall ipywidgets --only in terminal\n",
    "#!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "!jupyter serverextension enable voila --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a742b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating widgets for the deployement\n",
    "\n",
    "#Dropdown widget\n",
    "location = widgets.Dropdown(\n",
    "    options=['India','United States'],\n",
    "    value='India',\n",
    "    description='Location:',\n",
    ")\n",
    "\n",
    "job_profile = widgets.Dropdown(\n",
    "    options=['Data scientist','Software engineer'],\n",
    "    value='Data scientist',\n",
    "    description='Job Profile:',\n",
    ")\n",
    "\n",
    "#Text Widget\n",
    "profiles_required = widgets.Text(placeholder='Enter no of profiles',description='# of Profiles:')\n",
    "\n",
    "\n",
    "LOB = widgets.Dropdown(\n",
    "    options=['LOB_BFSI','LOB_CSMP','LOB_EAS','LOB_ERS','LOB_ETS','LOB_Healthcare','LOB_INFRA','LOB_MMS'],\n",
    "    value='LOB_BFSI',\n",
    "    description='LOB:',\n",
    ")\n",
    "\n",
    "\n",
    "Offered_band = widgets.Dropdown(\n",
    "    options=['Offered_band_E1','Offered_band_E2','Offered_band_E3'],\n",
    "    value='Offered_band_E1',\n",
    "    description='CTC Band:',\n",
    ")\n",
    "\n",
    "Candidate_ID = widgets.Text(placeholder='Candidate_ID',description='Candidate_ID')\n",
    "\n",
    "Profile_Link = widgets.Text(placeholder='Profile Link',description='Profile Link')\n",
    "\n",
    "Duration_to_accept_offer = widgets.Text(placeholder='Duration_to_accept_offer',description='Duration_to_accept_offer')\n",
    "\n",
    "Notice_period = widgets.Text(placeholder='Notice_period',description='Notice_period')\n",
    "\n",
    "Percent_difference_CTC = widgets.Text(placeholder='Percent_difference_CTC',description='Percent_difference_CTC')\n",
    "\n",
    "Rex_in_Yrs = widgets.Text(placeholder='Rex_in_Yrs',description='Rex_in_Yrs')\n",
    "\n",
    "Companies_Count = widgets.Text(placeholder='Companies_Count',description='Companies_Count')\n",
    "\n",
    "Proximity_to_Job_Location = widgets.Text(placeholder='Proximity_to_Job_Location',description='Proximity_to_Job_Location')\n",
    "\n",
    "Age = widgets.Text(placeholder='Age',description='Age')\n",
    "\n",
    "Match_Score = widgets.Text(placeholder='Match_Score',description='Match_Score')\n",
    "\n",
    "DOJ_Extended_Yes = widgets.Text(placeholder='DOJ_Extended_Yes',description='DOJ_Extended_Yes')\n",
    "\n",
    "Joining_Bonus_Yes = widgets.Text(placeholder='Joining_Bonus_Yes',description='Joining_Bonus_Yes')\n",
    "\n",
    "Candidate_relocate_actual_Yes = widgets.Text(placeholder='Candidate_relocate_actual_Yes',description='Candidate_relocate_actual_Yes')\n",
    "\n",
    "Gender_Male = widgets.Text(placeholder='Gender_Male',description='Gender_Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ef03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to fetch linkedin urls\n",
    "\n",
    "def get_urls(country_name,profile_name):\n",
    "    Country_name = country_name\n",
    "    Job_Profile = profile_name\n",
    "    \n",
    "    search_query = \"site:linkedin.com/in AND\" + Job_Profile + \" AND \" + Country_name\n",
    "    # Use a try-except block to handle the ImportError\n",
    "    try:\n",
    "        from googlesearch import search\n",
    "    except ImportError:\n",
    "        print(\"No module named 'google' found\")\n",
    "    \n",
    "    profile_link = []\n",
    "    for i, link in enumerate(search(search_query, num=5, stop=5, pause=2)):\n",
    "        # Check if the link is not already in the list\n",
    "        if link not in profile_link:\n",
    "            profile_link.append(link)\n",
    "            #print(f\"{i+1}. {link}\")\n",
    "\n",
    "\n",
    "    # Use pandas to write the list to a CSV file\n",
    "    column_names = ['LinkedIn_Profile_Links']\n",
    "    df = pd.DataFrame(profile_link,columns=column_names)\n",
    "    df['Candidate ID'] = df.index + 100\n",
    "    df['LinkedIn_Profile_Links'] = df['LinkedIn_Profile_Links'].replace({'in.l': 'www.l'}, regex=True)\n",
    "    df.to_csv(r'C:\\Users\\Deepak Gupta\\OneDrive - Indian School of Business\\Term 2\\Foundational Project 1\\Group Project\\Outputs\\linkedin_profile_links.csv',index = False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e959775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#defining the function to fetch data from linkedin\n",
    "\n",
    "def get_scrapped_data():\n",
    "    \n",
    "    PAGE_LOAD_TIME_WAIT_SEC = 20\n",
    "    CALL_WAIT_TIME_SEC = 10\n",
    "\n",
    "    EXP_PAGE_PATH = \"/details/experience\"\n",
    "    SKILLS_PAGE_PATH = \"/details/skills\"\n",
    "\n",
    "    INPUT_PROFILES_FILE_PATH = r'C:\\Users\\Deepak Gupta\\OneDrive - Indian School of Business\\Term 2\\Foundational Project 1\\Group Project\\Outputs\\linkedin_profile_links.csv'\n",
    "    PROFILE_DF_FILE = r'C:\\Users\\Deepak Gupta\\OneDrive - Indian School of Business\\Term 2\\Foundational Project 1\\Group Project\\Outputs\\linkedin_profile_dataframe.csv'\n",
    "    PROFILE_JSON_FILE = r'C:\\Users\\Deepak Gupta\\OneDrive - Indian School of Business\\Term 2\\Foundational Project 1\\Group Project\\Outputs\\linkedin_profile_json.csv'\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    \n",
    "    # driver.get method() will navigate to a page given by the URL address\n",
    "    driver.get('https://www.linkedin.com/')\n",
    "\n",
    "    # locate email form by_class_name\n",
    "    #username = driver.find_element(By.CLASS_NAME,'input__input')\n",
    "    username = driver.find_element(\"name\",'session_key')\n",
    "\n",
    "    # send_keys() to simulate key strokes\n",
    "    username.send_keys('gunika.kamra.ampba@gmail.com')\n",
    "\n",
    "    password = driver.find_element(\"name\",'session_password')\n",
    "    password.send_keys('isb@12345')\n",
    "\n",
    "    log_in_button = driver.find_element(By.CLASS_NAME,'sign-in-form__submit-button')\n",
    "    log_in_button.click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    profile_df = pd.read_csv(INPUT_PROFILES_FILE_PATH)\n",
    "\n",
    "    #Fetching name from the linkedin profile\n",
    "    def get_name_from_profile(soup):\n",
    "\n",
    "        if (soup.find('section', {'class':\"artdeco-card ember-view pv-top-card\"}) is None):\n",
    "            return \"\"\n",
    "\n",
    "        try:\n",
    "            name = soup.find('section', {'class':\"artdeco-card ember-view pv-top-card\"}) \\\n",
    "               .find('div',{'class':'mt2 relative'})\\\n",
    "               .find('h1',{'class':'text-heading-xlarge inline t-24 v-align-middle break-words'}).string.strip()\n",
    "            #print(name)\n",
    "            return name\n",
    "        except:\n",
    "            return \"\"\n",
    "        \n",
    "        \n",
    "#fetching location from the linkedin profile\n",
    "    def get_location_from_profile(soup):\n",
    "        location = \"\"\n",
    "\n",
    "        if ((soup.find('section', {'class':\"artdeco-card ember-view pv-top-card\"})) is None):\n",
    "            return location\n",
    "        try:\n",
    "            location = soup.find('section', {'class':\"artdeco-card ember-view pv-top-card\"}) \\\n",
    "               .find('div',{'class':'mt2 relative'})\\\n",
    "               .find('div',{'class':'pv-text-details__left-panel mt2'})\\\n",
    "               .find('span',{'class':'text-body-small inline t-black--light break-words'}).string.strip()\n",
    "            #print(location)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return location\n",
    "    \n",
    "\n",
    "#fetching descritions and about sections\n",
    "    def get_about_from_profile(soup,text_bagofwords):\n",
    "        about_text = \"\"\n",
    "\n",
    "        try:\n",
    "            cards =soup.find_all('section', {'class':\"artdeco-card ember-view relative break-words pb3 mt2\"})\n",
    "        except:\n",
    "            return about_text,text_bagofwords\n",
    "\n",
    "        for card in cards:\n",
    "            if (card.find('div',attrs={'id':'about'})):\n",
    "                try:\n",
    "                    about_div = card.find('div',attrs={'class':'inline-show-more-text inline-show-more-text--is-collapsed full-width'})\n",
    "                    about_text = re.sub(r'<.*>',\"\",str(about_div))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        text_bagofwords += about_text\n",
    "        return about_text, text_bagofwords\n",
    "\n",
    "    \n",
    "#fetching education background\n",
    "    def get_about_education_from_profile(soup,text_bagofwords):\n",
    "\n",
    "        educ_list = []\n",
    "\n",
    "        try:\n",
    "            cards =soup.find_all('section', {'class':\"artdeco-card ember-view relative break-words pb3 mt2\"})\n",
    "        except:\n",
    "            return educ_list\n",
    "\n",
    "        for card in cards:\n",
    "            if (card.find('div',attrs={'id':'about'})):\n",
    "                try:\n",
    "                    about_div = card.find('div',attrs={'class':'inline-show-more-text inline-show-more-text--is-collapsed full-width'})\n",
    "                    about_text = re.sub(r'<.*>',\"\",str(about_div))\n",
    "                    text_bagofwords += about_text\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            if(card.find('div',attrs={'id':'education'})):\n",
    "                edu_list = card.find_all('li',{'class':'artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "\n",
    "                for edu in edu_list:\n",
    "                    educ_dict = {}\n",
    "                    collegename_string = \"\"\n",
    "                    degreename_string = \"\"\n",
    "                    degreedate_string = \"\"\n",
    "\n",
    "                    try:\n",
    "                        collegename_div = edu.find('div',{'class':'display-flex flex-column full-width align-self-center'})\\\n",
    "                                        .find('span',{'class':'mr1 hoverable-link-text t-bold'})\\\n",
    "                                        .find('span',{'class':'visually-hidden'})\n",
    "                        collegename_string = re.sub('<.*?>',\"\",str(collegename_div))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        degreename_div = edu.find('div',{'class':'display-flex flex-column full-width align-self-center'})\\\n",
    "                                        .find('span',{'class':'t-14 t-normal'})\\\n",
    "                                        .find('span',{'class':'visually-hidden'})\n",
    "                        degreename_string = re.sub('<.*?>',\"\",str(degreename_div))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        degreedate_div = edu.find('div',{'class':'display-flex flex-column full-width align-self-center'})\\\n",
    "                                        .find('span',{'class':'t-14 t-normal t-black--light'})\\\n",
    "                                        .find('span',{'class':'visually-hidden'})\n",
    "                        degreedate_string = re.sub('<.*?>',\"\",str(degreedate_div))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    educ_dict[\"Name\"]=collegename_string\n",
    "                    educ_dict[\"Degree\"]=degreename_string\n",
    "                    educ_dict[\"Date\"]=degreedate_string\n",
    "                    educ_list.append(educ_dict)\n",
    "\n",
    "        return about, educ_list, text_bagofwords\n",
    "    \n",
    "\n",
    "\n",
    "    #Get Experience List\n",
    "    def get_experience_from_experience_page(soup,text_bagofwords):\n",
    "        job_list = []\n",
    "        total_exp_months = 0\n",
    "        companies_count = 0\n",
    "\n",
    "        if(soup.find('section',{'class':'artdeco-card ember-view pb3'})is None):\n",
    "            return total_exp_months, companies_count, text_bagofwords, job_list\n",
    "\n",
    "        try:\n",
    "            exp_list = soup.find('section',{'class':'artdeco-card ember-view pb3'})\\\n",
    "                    .find('div',{'class':'pvs-list__container'})\\\n",
    "                    .find_all('li',{'class':'pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated'})\n",
    "        except:\n",
    "            return total_exp_months, companies_count, text_bagofwords, job_list\n",
    "\n",
    "        companies_count = len(exp_list)\n",
    "        for job in exp_list:\n",
    "\n",
    "            #Different layouts depending on whether multiple roles within same company or 1 role in the company\n",
    "            if (job.find('div',{'class':'display-flex flex-column full-width'})):\n",
    "                job_dict ={}\n",
    "                designation = \"\"\n",
    "                company = \"\"\n",
    "                tenure = \"\"\n",
    "                location = \"\"\n",
    "                description_string = start_date = end_date = \"\"\n",
    "\n",
    "                #Designation field crawled\n",
    "                try:\n",
    "                    designation_div = job.find('div',{'class':'display-flex flex-column full-width'})\\\n",
    "                            .find('span',{'class':'mr1 t-bold'})\\\n",
    "                            .find('span',{'class':'visually-hidden'})\n",
    "                    designation = re.sub('<.*?>',\"\",str(designation_div))\n",
    "                except:\n",
    "                    pass\n",
    "                job_dict[\"Designation\"] = designation\n",
    "\n",
    "                #Company field crawled\n",
    "                try:\n",
    "                    company_div = job.find('div',{'class':'display-flex flex-column full-width'})\\\n",
    "                                .find('span',{'class':'t-14 t-normal'})\\\n",
    "                                .find('span',{'class':'visually-hidden'})\n",
    "                    company = re.sub('<.*?>',\"\",str(company_div))\n",
    "                except:\n",
    "                    pass\n",
    "                job_dict[\"Company\"] = company\n",
    "\n",
    "                #Tenure field crawled\n",
    "                duration_in_months = 0\n",
    "                try:\n",
    "                    tenure_div = job.find('div',{'class':'display-flex flex-column full-width'})\\\n",
    "                                .find('span',{'class':'t-14 t-normal t-black--light'})\\\n",
    "                                .find('span',{'class':'visually-hidden'})\n",
    "                    tenure = re.sub('<.*?>',\"\",str(tenure_div))\n",
    "                    job_dict[\"Tenure\"] = tenure\n",
    "                    match = re.search(r'(.*) - (.*) ·(.*)', tenure)\n",
    "                    if match:\n",
    "                        start_date = match.group(1)\n",
    "                        end_date = match.group(2)\n",
    "                        period = match.group(3)\n",
    "\n",
    "                        year_match = re.search(r'(\\d*) yr.*',period)\n",
    "                        months_match = re.search(r'(\\d*) mo.*',period)\n",
    "\n",
    "                        if year_match:\n",
    "                            years = int(year_match.group(1))\n",
    "                        else:\n",
    "                            years = 0\n",
    "                        if months_match:\n",
    "                            months = int(months_match.group(1))\n",
    "                        else:\n",
    "                            months = 0\n",
    "                        duration_in_months = years * 12 + months\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                total_exp_months += duration_in_months\n",
    "                job_dict[\"Start Date\"]=start_date\n",
    "                job_dict[\"End Date\"]=end_date\n",
    "                job_dict[\"Tenure Months\"]=duration_in_months\n",
    "\n",
    "\n",
    "                #location field crawled\n",
    "                try:\n",
    "                    location_div = job.find('div',{'class':'display-flex flex-column full-width'})\\\n",
    "                                .find('span',{'class':'t-14 t-normal t-black--light'})\\\n",
    "                                .findNext('span',{'class':'t-14 t-normal t-black--light'})\\\n",
    "                                .find('span',{'class':'visually-hidden'})\n",
    "                    location = re.sub('<.*?>',\"\",str(location_div))\n",
    "                    location_list = location.split(\",\")\n",
    "                    job_dict[\"Location\"] = location\n",
    "                    job_dict[\"City\"]=location_list[0]\n",
    "                except:\n",
    "                    pass\n",
    "                location_list = location.split(\",\")\n",
    "                job_dict[\"Location\"] = location\n",
    "                job_dict[\"City\"]=location_list[0]\n",
    "                if(len(location_list)>=2):\n",
    "                    job_dict[\"State\"]=location_list[1]\n",
    "                else:\n",
    "                    job_dict[\"State\"]=\"\"\n",
    "                if(len(location_list)>=3):\n",
    "                    job_dict[\"Country\"]=location_list[2]\n",
    "                else:\n",
    "                    job_dict[\"Country\"]=\"\"\n",
    "\n",
    "                #Details of job description crawled\n",
    "                try:\n",
    "                    description_div = job.find('ul',{'class':'pvs-list'})\\\n",
    "                                 .find_all('div',{'class':'pvs-list__outer-container'})\n",
    "                    description_string = start_date = end_date = \"\"\n",
    "                    for describe in description_div:\n",
    "                        try:\n",
    "                            describe_div = describe.find('div',{'class':'display-flex full-width'})\\\n",
    "                                       .find('div',{'class':'display-flex align-items-center t-14 t-normal t-black'})\\\n",
    "                                       .find('span',{'class':'visually-hidden'})\n",
    "                            description_string +=  re.sub('<.*?>',\"\",str(describe_div))\n",
    "                        except:\n",
    "                            pass       \n",
    "                except:\n",
    "                    pass\n",
    "                job_dict[\"Description\"] = description_string\n",
    "                job_list.append(job_dict)\n",
    "                text_bagofwords += designation+\" \"+description_string\n",
    "\n",
    "            else:\n",
    "                #Else loop for match with multiple roles in the same company\n",
    "                company_div = job.find('div',{'class':'display-flex flex-column full-width align-self-center'})\\\n",
    "                                .find('span',{'class':'mr1 hoverable-link-text t-bold'})\\\n",
    "                                .find('span',{'class':'visually-hidden'})\n",
    "                company = re.sub('<.*?>',\"\",str(company_div))\n",
    "\n",
    "                role_list = job.find('div',{'class':'pvs-list__outer-container'})\\\n",
    "                            .find('ul',{'class':'pvs-list'})\\\n",
    "                            .find_all('div',{'class','display-flex flex-column full-width align-self-center'})\n",
    "\n",
    "\n",
    "                for role in role_list:\n",
    "                    job_dict ={}\n",
    "                    designation_div = role.find('span',{'class':'mr1 hoverable-link-text t-bold'})\\\n",
    "                                .find('span',{'class':'visually-hidden'})\n",
    "                    designation = re.sub('<.*?>',\"\",str(designation_div))\n",
    "\n",
    "                    tenure_div = role.find('span',{'class':'t-14 t-normal t-black--light'})\\\n",
    "                                    .find('span',{'class':'visually-hidden'})\n",
    "                    tenure = re.sub('<.*?>',\"\",str(tenure_div))\n",
    "                    match = re.search(r'(.*) - (.*) ·(.*)', tenure)\n",
    "                    if match:\n",
    "                        start_date = match.group(1)\n",
    "                        end_date = match.group(2)\n",
    "                        period = match.group(3)\n",
    "\n",
    "                        year_match = re.search(r'(\\d*) yr.*',period)\n",
    "                        months_match = re.search(r'(\\d*) mo.*',period)\n",
    "\n",
    "                        if year_match:\n",
    "                            years = int(year_match.group(1))\n",
    "                        else:\n",
    "                            years = 0\n",
    "                        if months_match:\n",
    "                            months = int(months_match.group(1))\n",
    "                        else:\n",
    "                            months = 0\n",
    "\n",
    "                        duration_in_months = years * 12 + months\n",
    "                    else:\n",
    "                        duration_in_months = 0\n",
    "                        start_date = end_date = \"\"\n",
    "\n",
    "                    total_exp_months += duration_in_months\n",
    "\n",
    "                    try:\n",
    "                        location_div = role.find('span',{'class':'t-14 t-normal t-black--light'})\\\n",
    "                                    .findNext('span',{'class':'t-14 t-normal t-black--light'})\\\n",
    "                                    .find('span',{'class':'visually-hidden'})\n",
    "                        location = re.sub('<.*?>',\"\",str(location_div))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        describe_div = role.find('ul',{'class':'pvs-list'})\\\n",
    "                                           .find('div',{'class':'pvs-list__outer-container'})\\\n",
    "                                           .find('div',{'class':'display-flex full-width'})\\\n",
    "                                           .find('div',{'class':'display-flex align-items-center t-14 t-normal t-black'})\\\n",
    "                                           .find('span',{'class':'visually-hidden'})\n",
    "                        description_string =  re.sub('<.*?>',\"\",str(describe_div))\n",
    "                    except:\n",
    "                        description_string = \"\"\n",
    "                    job_dict[\"Company\"]=company\n",
    "                    job_dict[\"Designation\"]=designation\n",
    "                    job_dict[\"Start Date\"]=start_date\n",
    "                    job_dict[\"End Date\"]=end_date\n",
    "                    job_dict[\"Tenure Months\"]=duration_in_months\n",
    "                    job_dict[\"Tenure\"]=tenure\n",
    "                    job_dict[\"Location\"]=location\n",
    "\n",
    "                    location_list = location.split(\",\")\n",
    "                    job_dict[\"Location\"] = location\n",
    "                    job_dict[\"City\"]=location_list[0]\n",
    "                    if(len(location_list)>=2):\n",
    "                        job_dict[\"State\"]=location_list[1]\n",
    "                    else:\n",
    "                        job_dict[\"State\"] = \"\"\n",
    "                    if(len(location_list)>=3):\n",
    "                        job_dict[\"Country\"]=location_list[2]\n",
    "                    else:\n",
    "                        job_dict[\"Country\"]=\"\"\n",
    "                    job_dict[\"Description\"]=description_string\n",
    "                    text_bagofwords += designation+\" \"+description_string\n",
    "                    job_list.append(job_dict)\n",
    "\n",
    "\n",
    "\n",
    "        return total_exp_months, companies_count, text_bagofwords, job_list  \n",
    "    \n",
    "\n",
    "    #Code to get Skills from skills page\n",
    "    def get_skills_from_skills_page(soup,text_bag_of_words):\n",
    "        skill_string_list = []\n",
    "        skillname_string = \"\"\n",
    "\n",
    "        if(soup.find('ul',{'class':'pvs-list'}) is None):\n",
    "            return skill_string_list,text_bag_of_words\n",
    "\n",
    "        try:\n",
    "            skills_list = soup.find('ul',{'class':'pvs-list'})\\\n",
    "                       .find_all('li',{'class':'pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated'})\n",
    "        except:\n",
    "            return skill_string_list,text_bag_of_words\n",
    "\n",
    "        for skill in skills_list:  \n",
    "            skillname_div = skill.find('div',{'class':'display-flex flex-column full-width align-self-center'})\\\n",
    "                            .find('div',{'class':'display-flex align-items-center'})\\\n",
    "                            .find('span',{'class':'mr1 hoverable-link-text t-bold'})\\\n",
    "                            .find('span',{'class':'visually-hidden'})\n",
    "            skillname_string = re.sub('<.*?>',\"\",str(skillname_div))\n",
    "            text_bag_of_words += \" \"+skillname_string\n",
    "            skill_string_list.append(skillname_string)\n",
    "\n",
    "        return skill_string_list,text_bag_of_words\n",
    "\n",
    "#appending and merging all the fetched data into one dataframe\n",
    "    for i,row in profile_df.iterrows():\n",
    "        profile_dict = {}\n",
    "        profile_df_row = []\n",
    "        text_bagofwords = \"\"\n",
    "        about =\"\"\n",
    "        educ_list = []\n",
    "        profilecrawl_df = pd.DataFrame([],columns=['Candidate_ID','ProfileLink','Name','City','State','Country','Total_Experience_Months',\\\n",
    "                                              'Companies_Count','Text_BagofWords','skills_list'])   \n",
    "\n",
    "        profile_link = row['LinkedIn_Profile_Links']\n",
    "\n",
    "        profile_dict[\"Candidate_ID\"] = row['Candidate ID']\n",
    "        profile_dict[\"Profile_Link\"] = profile_link\n",
    "\n",
    "        #Load the Main Profile Page of the candidate\n",
    "        time.sleep(CALL_WAIT_TIME_SEC)\n",
    "        driver.get(profile_link)\n",
    "        time.sleep(PAGE_LOAD_TIME_WAIT_SEC)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "\n",
    "        #Load and Crawl the Main Profile Page of the candidate to get Name, Location, About, Education\n",
    "        profile_dict[\"Name\"] = get_name_from_profile(soup)\n",
    "\n",
    "        profile_dict[\"Location\"] = get_location_from_profile(soup)\n",
    "        profile_dict[\"City\"] = profile_dict[\"Location\"].split(',')[0]\n",
    "        #profile_dict[\"State\"] = profile_dict[\"Location\"].split(',')[1]\n",
    "        profile_dict[\"Country\"] = profile_dict[\"Location\"].split(',')[-1]\n",
    "\n",
    "\n",
    "        about, educ_list, text_bagofwords = get_about_education_from_profile(soup, text_bagofwords)\n",
    "        profile_dict[\"About\"] = about\n",
    "        profile_dict[\"Education\"] = educ_list\n",
    "\n",
    "\n",
    "        #Load and Crawl the Experience Page of the candidate\n",
    "        time.sleep(CALL_WAIT_TIME_SEC)\n",
    "        experience_page=profile_link+EXP_PAGE_PATH\n",
    "        driver.get(experience_page)\n",
    "        time.sleep(PAGE_LOAD_TIME_WAIT_SEC)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        total_exp_months, companies_count, text_bagofwords, job_list = get_experience_from_experience_page(soup,text_bagofwords)\n",
    "        profile_dict[\"Total_Experience_Months\"] = total_exp_months\n",
    "        profile_dict[\"Companies_Count\"] = companies_count\n",
    "        profile_dict[\"Experience\"] = job_list\n",
    "\n",
    "        #Load and Crawl the Skills Page of the candidate\n",
    "        time.sleep(CALL_WAIT_TIME_SEC)\n",
    "        skills_page=profile_link+SKILLS_PAGE_PATH\n",
    "        driver.get(skills_page)\n",
    "        time.sleep(PAGE_LOAD_TIME_WAIT_SEC)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        skills_list, text_bagofwords = get_skills_from_skills_page(soup,text_bagofwords)\n",
    "        profile_dict[\"Skills\"] = skills_list\n",
    "\n",
    "\n",
    "\n",
    "        #Append the Profile Dict json in file\n",
    "        with open(PROFILE_JSON_FILE, 'a', encoding ='utf8') as json_file:\n",
    "            json.dump(profile_dict, json_file, ensure_ascii = False,separators=(\",\",\":\"))\n",
    "\n",
    "        #Append the Profile df in the file    \n",
    "        profilecrawl_df.loc[0, 'Candidate_ID'] = profile_dict['Candidate_ID']\n",
    "        profilecrawl_df.loc[0, 'ProfileLink'] = profile_dict['Profile_Link']\n",
    "        profilecrawl_df.loc[0, 'Name'] = profile_dict['Name']\n",
    "        profilecrawl_df.loc[0, 'City'] = profile_dict['City']\n",
    "        #profilecrawl_df.loc[0, 'State'] = profile_dict['State']\n",
    "        profilecrawl_df.loc[0, 'Country'] = profile_dict['Country']\n",
    "        profilecrawl_df.loc[0, 'Total_Experience_Months'] = total_exp_months\n",
    "        profilecrawl_df.loc[0, 'Companies_Count'] = profile_dict['Companies_Count']\n",
    "        profilecrawl_df.loc[0, 'Text_BagofWords'] = text_bagofwords\n",
    "        profilecrawl_df.loc[0, 'skills_list'] = profile_dict[\"Skills\"]\n",
    "\n",
    "\n",
    "        profilecrawl_df.to_csv(PROFILE_DF_FILE, mode='a', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb68c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_maching(profile_name):\n",
    "    Script = pd.read_csv(r'C:\\Users\\Deepak Gupta\\OneDrive - Indian School of Business\\Term 2\\Foundational Project 1\\Group Project\\Outputs\\linkedin_profile_dataframe.csv')\n",
    "    #Converting text to lower case\n",
    "    \n",
    "    Script['skills_list']=Script['skills_list'].str.lower()\n",
    "    # # removing punctuation\n",
    "    Script['skills_list']=Script['skills_list'].astype(str).apply(lambda text: re.sub(r'[^\\w\\d\\s]','',text))\n",
    "    \n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    # Import stopwords with nltk.\n",
    "    from nltk.corpus import stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    \n",
    "    Script['skills_list'] = Script['skills_list'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "    Script['skills_list']=Script['skills_list'].replace(\"Skills\",\"\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if profile_name == profile_name:\n",
    "        Script['DATA_SCIENCE_REQUIRED_JD']=\"'Artificial Intelligence (AI)', 'Analytics', 'SAS', 'R', 'Microsoft Excel',  'Business Intelligence', 'Machine Learning', 'Strategy analytics', 'Analytical Skills', 'Campaign Management', 'Modeling',  'Building Automation', 'Python',  'Flask',  'Deep Learning', 'Django', 'API', 'Deployment', 'Artificial Intelligence', 'Machine Learning', 'Data Mining', 'Pattern Recognition', 'Algorithms', 'Analytics', 'Text Mining', 'MapReduce', 'Information Retrieval', 'Statistical Modeling', 'Big Data', 'Predictive Analytics', 'Optimization', 'Distributed Systems', 'Natural Language Processing', 'Image Processing', 'Computer Vision', 'Recommender Systems', 'Statistics', 'Time Series Analysis','NLP','AWS Glue', 'AWS Lambda', 'Amazon S3', 'Python (Programming Language)'\"\n",
    "    else:\n",
    "        Script['DATA_SCIENCE_REQUIRED_JD']=\"'Software', 'Engineer','Java','C++','C'\"\n",
    "        \n",
    "        \n",
    "    #Converting text to lower case\n",
    "    Script['DATA_SCIENCE_REQUIRED_JD']=Script['DATA_SCIENCE_REQUIRED_JD'].str.lower()\n",
    "    # # removing punctuation\n",
    "    Script['DATA_SCIENCE_REQUIRED_JD']=Script['DATA_SCIENCE_REQUIRED_JD'].astype(str).apply(lambda text: re.sub(r'[^\\w\\d\\s]','',text))\n",
    "    Script['DATA_SCIENCE_REQUIRED_JD']= Script['DATA_SCIENCE_REQUIRED_JD'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    \n",
    "    \n",
    "    # Match_Test=[Script['skills_list'],Script['skills_list_wo_stp']]\n",
    "    Script[\"Match_key_word\"] = Script.apply(lambda x: \" \".join(i for i in x[\"DATA_SCIENCE_REQUIRED_JD\"].split() if i in x[\"skills_list\"]),axis=1) \n",
    "\n",
    "    Script[\"Matched_wrds\"] = Script[\"Match_key_word\"].apply(lambda n: len(n.split()))\n",
    "    \n",
    "    Script[\"Total_wrds\"] = Script[\"DATA_SCIENCE_REQUIRED_JD\"].apply(lambda n: len(n.split()))\n",
    "    \n",
    "    Script[\"Percent_match\"] = Script[\"Matched_wrds\"]/Script[\"Total_wrds\"]\n",
    "    \n",
    "    #Filter where match perecent is greater than 20%\n",
    "    Script = Script[Script['Percent_match'] >= 0.05] \n",
    "    \n",
    "    Script.to_csv(r'C:\\Users\\Deepak Gupta\\OneDrive - Indian School of Business\\Term 2\\Foundational Project 1\\Group Project\\Outputs\\Shortlisted_profiles.csv', header=True, index=False)\n",
    "    \n",
    "    Script_output = Script[['Candidate_ID','ProfileLink','Name','Percent_match']]\n",
    "    print(tabulate(Script_output,headers = 'keys',tablefmt = 'psql'))\n",
    "    #print(Script_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62901f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4edadbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#created a pickel to call the model\n",
    "def prediction(X):\n",
    "    with open(r'C:\\Users\\Deepak Gupta\\OneDrive - Indian School of Business\\Term 2\\Foundational Project 1\\Group Project\\model1.pkl', 'rb') as f:\n",
    "        clf2 = pickle.load(f)\n",
    "\n",
    "    clf2.predict(X[0:1])\n",
    "    if (clf2.predict(X[0:1])[0]) == 1:\n",
    "        print(\"Candidate will accept the offer\")\n",
    "    else:\n",
    "        print(\"Candidate will most probably reject the offer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f69dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the buttons to call the functions\n",
    "\n",
    "button_send_2 = widgets.Button(\n",
    "                description='Submit',\n",
    "                tooltip='Send',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "\n",
    "output_2 = widgets.Output()\n",
    "\n",
    "def on_button_clicked(event):\n",
    "    with output_2:\n",
    "        clear_output()\n",
    "        print(\"Fetching LinkedIn Profiles Urls\")\n",
    "        country_name=location.value\n",
    "        #print(country_name)\n",
    "        profile_name=job_profile.value\n",
    "        #profiles_required = profiles_required.value\n",
    "        #{grand.value}\n",
    "        get_urls(country_name,profile_name)\n",
    "        #print(\"url found\")\n",
    "        get_scrapped_data()\n",
    "        #print(\"profiles scraped\")\n",
    "        text_maching(profile_name)\n",
    "        #print(\"text matching done\")\n",
    "\n",
    "button_send_2.on_click(on_button_clicked)\n",
    "\n",
    "vbox_result = widgets.VBox([button_send_2, output_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dba3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a299422",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_send = widgets.Button(\n",
    "                description='Predict',\n",
    "                tooltip='Send',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "\n",
    "button_send_1 = widgets.Button(\n",
    "                description='Submit Candidate ID',\n",
    "                tooltip='Send',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "\n",
    "output = widgets.Output()\n",
    "output_1 = widgets.Output()\n",
    "\n",
    "\n",
    "def candidate_id(event):\n",
    "    with output_1:\n",
    "        clear_output()\n",
    "        shortlisted = pd.read_csv(r'C:\\Users\\Deepak Gupta\\OneDrive - Indian School of Business\\Term 2\\Foundational Project 1\\Group Project\\Outputs\\Shortlisted_profiles.csv')\n",
    "        shortlisted['Candidate_ID'] = shortlisted['Candidate_ID'].astype(str)\n",
    "        shortlisted = shortlisted[shortlisted['Candidate_ID']==Candidate_ID.value]\n",
    "        print(tabulate(shortlisted[['ProfileLink','Total_Experience_Months','Companies_Count','Percent_match']],headers = 'keys',tablefmt = 'psql'))\n",
    "        #print(shortlisted[['ProfileLink','Total_Experience_Months','Companies_Count','Percent_match']])\n",
    "        \n",
    "\n",
    "button_send_1.on_click(candidate_id)\n",
    "vbox_result_1 = widgets.VBox([button_send_1, output_1])\n",
    "\n",
    "\n",
    "def on_button_clicked(event):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        #print(\"Submit successfully\")\n",
    "        shortlisted = pd.read_csv(r'C:\\Users\\Deepak Gupta\\OneDrive - Indian School of Business\\Term 2\\Foundational Project 1\\Group Project\\Outputs\\Shortlisted_profiles.csv')\n",
    "        shortlisted['Candidate_ID'] = shortlisted['Candidate_ID'].astype(str)\n",
    "        shortlisted = shortlisted[shortlisted['Candidate_ID']==Candidate_ID.value]\n",
    "        X = pd.read_csv(r'C:\\Users\\Deepak Gupta\\OneDrive - Indian School of Business\\Term 2\\Foundational Project 1\\Group Project\\sample.csv')        \n",
    "        \n",
    "        X['Duration_to_accept_offer'] = X['Duration_to_accept_offer'].astype(str)\n",
    "        X['Duration_to_accept_offer'] = [Duration_to_accept_offer.value]\n",
    "        X['Notice_period'] = [Notice_period.value]\n",
    "        X['Percent_difference_CTC'] = [Percent_difference_CTC.value]\n",
    "        X['Rex_in_Yrs'] = [shortlisted['Total_Experience_Months']/12]\n",
    "        X['Companies_Count'] = [shortlisted['Companies_Count']]\n",
    "        X['Proximity_to_Job_Location'] = [Proximity_to_Job_Location.value]\n",
    "        X['Age'] = [Age.value]\n",
    "        X['Match_Score'] = [shortlisted['Percent_match']]\n",
    "        X['DOJ_Extended_Yes'] = [DOJ_Extended_Yes.value]\n",
    "        X['Offered_band_E1'] = 0\n",
    "        X['Offered_band_E2'] = 0\n",
    "        X['Offered_band_E3'] = 0\n",
    "        if Offered_band.value == \"Offered_band_E1\":\n",
    "             X['Offered_band_E1'] = 1\n",
    "        elif Offered_band.value == \"Offered_band_E2\":\n",
    "             X['Offered_band_E2'] = 1\n",
    "        elif Offered_band.value == \"Offered_band_E3\":\n",
    "             X['Offered_band_E3'] = 1\n",
    "        else:\n",
    "            X['Offered_band_E3'] = 1\n",
    "        \n",
    "        X['Joining_Bonus_Yes'] = [Joining_Bonus_Yes.value]\n",
    "        X['Candidate_relocate_actual_Yes'] = [Candidate_relocate_actual_Yes.value]\n",
    "        X['Gender_Male'] = [Gender_Male.value]\n",
    "        X['LOB_BFSI'] = 0\n",
    "        X['LOB_CSMP'] = 0\n",
    "        X['LOB_EAS'] = 0\n",
    "        X['LOB_ERS'] = 0\n",
    "        X['LOB_ETS'] = 0\n",
    "        X['LOB_Healthcare'] = 0\n",
    "        X['LOB_INFRA'] = 0\n",
    "        X['LOB_MMS'] = 0\n",
    "        if LOB.value == \"LOB_BFSI\":\n",
    "            X['LOB_BFSI'] = 1\n",
    "        elif LOB.value == \"LOB_CSMP\":\n",
    "            X['LOB_CSMP'] = 1\n",
    "        elif LOB.value == \"LOB_EAS\":\n",
    "            X['LOB_EAS'] = 1\n",
    "        elif LOB.value == \"LOB_ERS\":\n",
    "            X['LOB_ERS'] = 1\n",
    "        elif LOB.value == \"LOB_ETS\":\n",
    "            X['LOB_ETS'] = 1\n",
    "        elif LOB.value == \"LOB_Healthcare\":\n",
    "            X['LOB_Healthcare'] = 1\n",
    "        elif LOB.value == \"LOB_INFRA\":\n",
    "            X['LOB_INFRA'] = 1\n",
    "        elif LOB.value == \"LOB_MMS\":\n",
    "            X['LOB_MMS'] = 1\n",
    "        else:\n",
    "            X['LOB_MMS'] = 0\n",
    "        \n",
    "        prediction(X)\n",
    "        print(\"prediction is done\")\n",
    "\n",
    "\n",
    "button_send.on_click(on_button_clicked)\n",
    "\n",
    "vbox_result_2 = widgets.VBox([button_send, output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "279debed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving the headers of each page\n",
    "\n",
    "text_0 = widgets.HTML(value=\"<h1>Get Profiles</h1>\")\n",
    "text_1 = widgets.HTML(value=\"<h1>Enter Candidate ID</h1>\")\n",
    "text_2 = widgets.HTML(value=\"<h1>Use for prediction</h1>\")\n",
    "\n",
    "#assigning respective widgets to respective pages\n",
    "vbox_text = widgets.VBox([text_0, job_profile, location,profiles_required,vbox_result])\n",
    "vbox_text_1 = widgets.VBox([text_1, Candidate_ID ,vbox_result_1])\n",
    "vbox_text_2 = widgets.VBox([text_2, Candidate_ID ,Percent_difference_CTC,Proximity_to_Job_Location,Age,Duration_to_accept_offer,Notice_period,DOJ_Extended_Yes,Offered_band,Joining_Bonus_Yes,Candidate_relocate_actual_Yes,Gender_Male,LOB,vbox_result_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd9cc512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a71cfe11ef45c18dc88ffede222098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h1>Get Profiles</h1>'), Dropdown(description='Job Profile:', option…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42abef0c11da4862804a6b31ccc76e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h1>Enter Candidate ID</h1>'), Text(value='', description='Candidate…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5918c40e53b42eab4507e20f90446fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h1>Use for prediction</h1>'), Text(value='', description='Candidate…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displaying the final deployment\n",
    "\n",
    "page = widgets.HBox([vbox_text])\n",
    "page_1 = widgets.HBox([vbox_text_1])\n",
    "page_2 = widgets.HBox([vbox_text_2])\n",
    "display(page,page_1,page_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be982fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
